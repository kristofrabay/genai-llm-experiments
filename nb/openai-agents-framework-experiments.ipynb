{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing OpenAI's new Agents SDK\n",
    "\n",
    "OpenAI announced on March 11th, 2025 new Responses API and Agents SDK (https://openai.com/index/new-tools-for-building-agents/) \n",
    "\n",
    "This notebook aims to test these new products\n",
    "\n",
    "Main documentation: https://platform.openai.com/docs/guides/agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import base64\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "from agents import Agent, Runner, ModelSettings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components\n",
    "\n",
    "1. Agents\n",
    "\n",
    "    - Very similar to Responses API - actually built on it.\n",
    "    - Arguments (important ones):\n",
    "        - `instructions` - developer/system message. Can also be dynamic with a function that takes as input the context and reads from it to fill a prompt template\n",
    "        - `tools` - custom and built-in\n",
    "        - `output_type` - structured output objects\n",
    "        - `handoff_description` - description of the agent. This is used when the agent is used as a handoff, so that an LLM knows what it does and when to invoke it.\n",
    "    - Run them via the `Runner` class (async by default)\n",
    "        - handles e2e flow - no manual tool execution or handoff is needed. it is done once reached a `final_output` return\n",
    "\n",
    "2. Tools\n",
    "    - `function–tool` decorator - turn functions (well defined!) into JSON schemas\n",
    "\n",
    "3. Handoffs\n",
    "    - basically sub-agents (technically tools / functions) that are being called when an agent-to-agent handoff should happen\n",
    "    - in handoffs, the new agent receives the **entire conversation history**, tools (or agents-as-tools) **only receive the generated output**\n",
    "\n",
    "4. Output types ~ Structured outputs\n",
    "    - pydantic Baseclasses passed to agent under `output_type`\n",
    "\n",
    "5. Context\n",
    "    - dataclass that is passed to all agents, handoffs, tools\n",
    "    - everyone can read from it, fill prompt templates, pass parameters\n",
    "\n",
    "6. Additionals\n",
    "    1. Guardrails\n",
    "    2. Lifecycle events (hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First tests - very basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(agent, user_input):\n",
    "    \n",
    "    result = await Runner.run(agent, user_input)\n",
    "    print(result.final_output)\n",
    "\n",
    "    return result\n",
    "    \n",
    "agent = Agent(\n",
    "    name=\"Funny guy\", \n",
    "    instructions=\"You are a helpful assistant that always responds in a humorous manner\",\n",
    "    model = \"gpt-4o\",\n",
    "    model_settings = ModelSettings(temperature=0.0),\n",
    "    #handoff_description = None, # A description of the agent.\n",
    "    #handoffs = [], # Sub-agents that the agent can delegate to. \n",
    "    #tools = [], # A list of tools that the agent can use.\n",
    "    #input_guardrails = [],\n",
    "    #output_guardrails = [],\n",
    "    #output_type = None, # The type of the output object. If not provided, the output will be `str`.\n",
    "    )\n",
    "\n",
    "user_input = \"Write a haiku about recursion in programming.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code calls itself, loops,  \n",
      "In endless self-reference—  \n",
      "Oops, stack overflow!\n"
     ]
    }
   ],
   "source": [
    "r = await main(agent, user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Write a haiku about recursion in programming.',\n",
       " 'new_items': [MessageOutputItem(agent=Agent(name='Funny guy', instructions='You are a helpful assistant that always responds in a humorous manner', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=0.0, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None), raw_item=ResponseOutputMessage(id='msg_67d57700ae888192a8858fe6a242451c084aa909d0d06bfd', content=[ResponseOutputText(annotations=[], text='Code calls itself, loops,  \\nIn endless self-reference—  \\nOops, stack overflow!', type='output_text')], role='assistant', status='completed', type='message'), type='message_output_item')],\n",
       " 'raw_responses': [ModelResponse(output=[ResponseOutputMessage(id='msg_67d57700ae888192a8858fe6a242451c084aa909d0d06bfd', content=[ResponseOutputText(annotations=[], text='Code calls itself, loops,  \\nIn endless self-reference—  \\nOops, stack overflow!', type='output_text')], role='assistant', status='completed', type='message')], usage=Usage(requests=1, input_tokens=50, output_tokens=19, total_tokens=69), referenceable_id='resp_67d57700548881929b6c352027daa710084aa909d0d06bfd')],\n",
       " 'final_output': 'Code calls itself, loops,  \\nIn endless self-reference—  \\nOops, stack overflow!',\n",
       " 'input_guardrail_results': [],\n",
       " 'output_guardrail_results': [],\n",
       " '_last_agent': Agent(name='Funny guy', instructions='You are a helpful assistant that always responds in a humorous manner', handoff_description=None, handoffs=[], model='gpt-4o', model_settings=ModelSettings(temperature=0.0, top_p=None, frequency_penalty=None, presence_penalty=None, tool_choice=None, parallel_tool_calls=False, truncation=None, max_tokens=None), tools=[], input_guardrails=[], output_guardrails=[], output_type=None, hooks=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
