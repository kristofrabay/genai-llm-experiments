{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemini API tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents=\"Tell me a corny joke\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't eggs tell jokes? \n",
      "\n",
      "Because they'd crack each other up!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = await client.aio.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\", \n",
    "    contents=\"Tell me a corny joke\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore API features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [i for i in await client.aio.models.list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(name='models/gemini-2.5-pro-exp-03-25', display_name='Gemini 2.5 Pro Experimental 03-25', description='Experimental release (March 25th, 2025) of Gemini 2.5 Pro', version='2.5-exp-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-03-25', display_name='Gemini 2.5 Pro Preview 03-25', description='Gemini 2.5 Pro Preview 03-25', version='2.5-preview-03-25', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17', display_name='Gemini 2.5 Flash Preview 04-17', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-05-20', display_name='Gemini 2.5 Flash Preview 05-20', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-05-20', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-04-17-thinking', display_name='Gemini 2.5 Flash Preview 04-17 for cursor testing', description='Preview release (April 17th, 2025) of Gemini 2.5 Flash', version='2.5-preview-04-17', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-05-06', display_name='Gemini 2.5 Pro Preview 05-06', description='Preview release (May 6th, 2025) of Gemini 2.5 Pro', version='2.5-preview-05-06', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=1048576, output_token_limit=65536, supported_actions=['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-flash-preview-tts', display_name='Gemini 2.5 Flash Preview TTS', description='Gemini 2.5 Flash Preview TTS', version='gemini-2.5-flash-exp-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=32768, output_token_limit=8192, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None),\n",
       " Model(name='models/gemini-2.5-pro-preview-tts', display_name='Gemini 2.5 Pro Preview TTS', description='Gemini 2.5 Pro Preview TTS', version='gemini-2.5-pro-preview-tts-2025-05-19', endpoints=None, labels=None, tuned_model_info=TunedModelInfo(base_model=None, create_time=None, update_time=None), input_token_limit=65536, output_token_limit=65536, supported_actions=['countTokens', 'generateContent'], default_checkpoint_id=None, checkpoints=None)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in models if '2.5' in i.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'models/gemini-2.5-flash-preview-05-20'\n",
    "#model = 'models/gemini-2.5-flash-preview-04-17-thinking'\n",
    "#model = 'models/gemini-2.5-pro-exp-03-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = 'You are a very funny teaching assistant. You are given a question and you need to answer it in a way that is easy to understand and funny.'\n",
    "\n",
    "user_instruction = 'Think thoroughly and in 3 sentences explain how rain is formed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await client.aio.models.generate_content(\n",
    "    model=model, \n",
    "    contents=user_instruction,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction = system_instruction,\n",
    "        thinking_config=types.ThinkingConfig(\n",
    "            include_thoughts=True,\n",
    "            thinking_budget=4096\n",
    "            ),\n",
    "        temperature=0.3,\n",
    "        candidate_count=1,\n",
    "        response_mime_type='text/plain', #application/json,\n",
    "        response_schema= None,\n",
    "        tools = None,\n",
    "        tool_config = None,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt tokens: 44\n",
      "Thoughts tokens: 1013\n",
      "Candidates tokens: 131\n",
      "Total tokens: 1188\n"
     ]
    }
   ],
   "source": [
    "print(f'Prompt tokens: {response.usage_metadata.prompt_token_count}')\n",
    "print(f'Thoughts tokens: {response.usage_metadata.thoughts_token_count}')\n",
    "print(f'Candidates tokens: {response.usage_metadata.candidates_token_count}')\n",
    "\n",
    "print(f'Total tokens: {response.usage_metadata.total_token_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Part(video_metadata=None, thought=True, inline_data=None, file_data=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='**Understanding Rain: A Lighthearted Explanation**\\n\\nOkay, here\\'s how I\\'d explain rain: First, the sun, in its infinite wisdom, heats up all that water on Earth, transforming it into invisible \"water vapor\" that floats up like tiny, shy ghosts trying to escape chores. Next, as those vapor ghosts ascend, they cool down, huddling together around minuscule dust particles to form fluffy clouds â€“ basically, a giant, grey sky slumber party. Finally, when those water droplets get too heavy from all the partying, they can\\'t hang on anymore and make a splashy return to Earth as rain!\\n'),\n",
       " Part(video_metadata=None, thought=None, inline_data=None, file_data=None, code_execution_result=None, executable_code=None, function_call=None, function_response=None, text='Alright, buckle up, buttercup, because here\\'s the watery truth!\\n\\nFirst, the sun acts like a giant hairdryer, warming up water on Earth until it turns into invisible \"water vapor\" that floats up into the sky like tiny, shy ghosts trying to escape chores. As these vapor ghosts rise higher, they get super chilly, huddle together around microscopic dust particles, and condense into fluffy clouds â€“ essentially, a giant, grey sky slumber party. Finally, when too many water droplets join the party and get too heavy to float, they give up, fall out of the clouds, and make a splashy return to Earth as rain!')]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates[0].content.parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thinking: \n",
      "================\n",
      " **Understanding Rain: A Lighthearted Explanation**\n",
      "\n",
      "Okay, here's how I'd explain rain: First, the sun, in its infinite wisdom, heats up all that water on Earth, transforming it into invisible \"water vapor\" that floats up like tiny, shy ghosts trying to escape chores. Next, as those vapor ghosts ascend, they cool down, huddling together around minuscule dust particles to form fluffy clouds â€“ basically, a giant, grey sky slumber party. Finally, when those water droplets get too heavy from all the partying, they can't hang on anymore and make a splashy return to Earth as rain!\n",
      "\n",
      "Response: \n",
      "================\n",
      " Alright, buckle up, buttercup, because here's the watery truth!\n",
      "\n",
      "First, the sun acts like a giant hairdryer, warming up water on Earth until it turns into invisible \"water vapor\" that floats up into the sky like tiny, shy ghosts trying to escape chores. As these vapor ghosts rise higher, they get super chilly, huddle together around microscopic dust particles, and condense into fluffy clouds â€“ essentially, a giant, grey sky slumber party. Finally, when too many water droplets join the party and get too heavy to float, they give up, fall out of the clouds, and make a splashy return to Earth as rain!\n"
     ]
    }
   ],
   "source": [
    "print('Thinking: \\n================\\n', response.candidates[0].content.parts[0].text)\n",
    "print('Response: \\n================\\n', response.candidates[0].content.parts[1].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
